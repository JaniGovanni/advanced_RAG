{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root directory to the Python path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Use the current working directory as the project root\n",
    "project_root = os.path.abspath('/Users/jan/Desktop/advanced_rag/')\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import json\n",
    "from app.doc_processing import process_doc, ProcessDocConfig\n",
    "from app.vectorstore import get_chroma_store_as_retriever, add_docs_to_store\n",
    "from app.chat import ChatConfig, get_result_docs, create_RAG_output\n",
    "import app.llm\n",
    "from app.test.end_to_end_eval import evaluate_answer\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRAGEvaluation(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Set up the document processing and store creation\n",
    "        cls.retriever = get_chroma_store_as_retriever()\n",
    "        cls.evaluation_data = cls.load_jsonl('app/test/evaluation_set.jsonl', num_lines=10)\n",
    "        cls.add_golden_docs_to_store()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_jsonl(file_path, num_lines=None):\n",
    "        \"\"\"\n",
    "        Reads the specified number of lines from the jsonl file and returns a list of dictionaries.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if num_lines is not None and i >= num_lines:\n",
    "                    break\n",
    "                data.append(json.loads(line))\n",
    "        return data\n",
    "    \n",
    "    @classmethod\n",
    "    def add_golden_docs_to_store(cls):\n",
    "        for entry in cls.evaluation_data:\n",
    "            golden_docs = entry['golden_documents']\n",
    "        for doc in golden_docs:\n",
    "            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as temp_file:\n",
    "                temp_file.write(doc['content'])\n",
    "                temp_file_path = temp_file.name\n",
    "\n",
    "            try:\n",
    "                config = ProcessDocConfig(\n",
    "                    tag=\"test\",\n",
    "                    local=True,\n",
    "                    filepath=temp_file_path,\n",
    "                    url=None,\n",
    "                    situate_context=False\n",
    "                )\n",
    "                # Process the golden document content\n",
    "                processed_chunks = process_doc(config)\n",
    "                # Add processed chunks to the vector store\n",
    "                add_docs_to_store(cls.retriever, processed_chunks)\n",
    "            finally:\n",
    "                # Ensure the temporary file is removed\n",
    "                os.unlink(temp_file_path)\n",
    "\n",
    "    \n",
    "    # def test_retrieval_accuracy(self):\n",
    "    #     for entry in self.evaluation_data:\n",
    "    #         query = entry['query']\n",
    "    #         golden_docs = entry['golden_documents']\n",
    "            \n",
    "    #         config = ChatConfig(tag=\"test\", k=5, llm=app.llm.get_ollama_llm())\n",
    "    #         result_docs, _ = get_result_docs(config, query)\n",
    "            \n",
    "    #     # Check if any of the retrieved documents match the golden documents\n",
    "    #     retrieved_content = [doc.page_content for doc in result_docs]\n",
    "    #     golden_content = [doc['content'] for doc in golden_docs]\n",
    "        \n",
    "    #     self.assertTrue(any(gold in retrieved for gold in golden_content for retrieved in retrieved_content),\n",
    "    #                     f\"Failed to retrieve golden document for query: {query}\")\n",
    "\n",
    "def test_answer_relevance(self):  # Changed from 'test_answer_relevance'\n",
    "    for entry in self.evaluation_data:\n",
    "        query = entry['query']\n",
    "        expected_answer = entry['answer']\n",
    "        \n",
    "        config = ChatConfig(tag=\"test\", k=5, llm=app.llm.get_groq_llm())\n",
    "        config.history_awareness(False)\n",
    "        result_docs, _ = get_result_docs(config, query)\n",
    "        context = ''.join([doc.page_content for doc in result_docs])\n",
    "        final_answer = create_RAG_output(context, query, config.llm)\n",
    "        \n",
    "        relevance_score = evaluate_answer(query, final_answer, expected_answer)\n",
    "        self.assertGreaterEqual(relevance_score, 70,\n",
    "                                f\"Low relevance score ({relevance_score}) for query: {query}\")\n",
    "\n",
    "def test_processing_time(self):\n",
    "    import time\n",
    "    for entry in self.evaluation_data:\n",
    "        query = entry['query']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        config = ChatConfig(tag=\"test\", k=5, llm=app.llm.get_groq_llm())\n",
    "        _, _ = get_result_docs(config, query)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        processing_time = end_time - start_time\n",
    "        self.assertLess(processing_time, 10,  # Adjust the threshold as needed\n",
    "                        f\"Processing time too long ({processing_time:.2f}s) for query: {query}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
